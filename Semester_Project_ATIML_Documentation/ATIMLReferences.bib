@article{Huang2017,
abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L2+1) direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.},
archivePrefix = {arXiv},
arxivId = {1608.06993},
author = {Huang, Gao and Liu, Zhuang and {Van Der Maaten}, Laurens and Weinberger, Kilian Q.},
doi = {10.1109/CVPR.2017.243},
eprint = {1608.06993},
file = {:C$\backslash$:/Users/Lenovo/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2017 - Densely connected convolutional networks.pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
pages = {2261--2269},
title = {{Densely connected convolutional networks}},
volume = {2017-Janua},
year = {2017}
}
@article{Worsham2018,
abstract = {Recent advances in Natural Language Processing are finding ways to place an emphasis on the hierarchical nature of text instead of representing language as a flat sequence or unordered collection of words or letters. A human reader must capture multiple levels of abstraction and meaning in order to formulate an understanding of a document. In this paper, we address the problem of developing approaches which are capable of working with extremely large and complex literary documents to perform Genre Identification. The task is to assign the literary classification to a full-length book belonging to a corpus of literature, where the works on average are well over 200,000 words long and genre is an abstract thematic concept. We introduce the Gutenberg Dataset for Genre Identification. Additionally, we present a study on how current deep learning models compare to traditional methods for this task. The results are presented as a baseline along with findings on how using an ensemble of chapters can significantly improve results in deep learning methods. The motivation behind the ensemble of chapters method is discussed as the compositionality of subtexts which make up a larger work and contribute to the overall genre.},
author = {Worsham, Joseph and Kalita, Jugal},
file = {:D$\backslash$:/ATIML/NLP using ML {\&} IDL.pdf:pdf},
pages = {1963--1973},
title = {{Genre Identification and the Compositional Effect of Genre in Literature}},
year = {2018}
}
@article{Garg2014,
abstract = {This paper focuses on classifying tweets based on the sentiments expressed in them, with the aim to classify them into three categories: positive, negative and neutral. In particular, we investigate the relevance of using a two-step classifier and negation detection in the space of Twitter Sentiment analysis. An efficient sentiment analyzer is deemed to be a must in the era of big data where preponderance of electronic communication is a major bottleneck. Major difficulties in handling of tweets are, their limited size, and the cryptic style of writing that makes them difficult to comprehend at times. We have used different datasets publicly available online and designed a comprehensive set of pre-processing steps that make the tweets more amenable to Natural Language Processing techniques. Two classifiers are designed based on Naive-Bayes and Maximum Entropy classifiers, and their accuracies are compared on different feature sets. We feel that such classifiers will help business or corporate houses, political parties or analysts etc. to evaluate public sentiments about them and design appropriate policies to address their concerns.},
author = {Garg, Yogesh and Chatterjee, Niladri},
doi = {10.1007/978-3-319-13820-6},
file = {:D$\backslash$:/ATIML/Sentiment11.pdf:pdf},
isbn = {9783319138190},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {33--52},
title = {{Sentiment analysis of twitter feeds}},
volume = {8883},
year = {2014}
}
@article{Pak2010,
abstract = {Microblogging today has become a very popular communication tool among Internet users. Millions of users share opinions on different aspects of life everyday. Therefore microblogging web-sites are rich sources of data for opinion mining and sentiment analysis. Because microblogging has appeared relatively recently, there are a few research works that were devoted to this topic. In our paper, we focus on using Twitter, the most popular microblogging platform, for the task of sentiment analysis. We show how to automatically collect a corpus for sentiment analysis and opinion mining purposes. We perform linguistic analysis of the collected corpus and explain discovered phenomena. Using the corpus, we build a sentiment classifier, that is able to determine positive, negative and neutral sentiments for a document. Experimental evaluations show that our proposed techniques are efficient and performs better than previously proposed methods. In our research, we worked with English, however, the proposed technique can be used with any other language.},
author = {Pak, Alexander and Paroubek, Patrick},
doi = {10.17148/ijarcce.2016.51274},
file = {:D$\backslash$:/ATIML/Sentiment.pdf:pdf},
isbn = {2951740867},
journal = {Proceedings of the 7th International Conference on Language Resources and Evaluation, LREC 2010},
pages = {1320--1326},
title = {{Twitter as a corpus for sentiment analysis and opinion mining}},
year = {2010}
}
@article{Can2018,
abstract = {Sentiment analysis is a widely studied NLP task where the goal is to determine opinions, emotions, and evaluations of users towards a product, an entity or a service that they are reviewing. One of the biggest challenges for sentiment analysis is that it is highly language dependent. Word embeddings, sentiment lexicons, and even annotated data are language specific. Further, optimizing models for each language is very time consuming and labor intensive especially for recurrent neural network models. From a resource perspective, it is very challenging to collect data for different languages. In this paper, we look for an answer to the following research question: can a sentiment analysis model trained on a language be reused for sentiment analysis in other languages, Russian, Spanish, Turkish, and Dutch, where the data is more limited? Our goal is to build a single model in the language with the largest dataset available for the task, and reuse it for languages that have limited resources. For this purpose, we train a sentiment analysis model using recurrent neural networks with reviews in English. We then translate reviews in other languages and reuse this model to evaluate the sentiments. Experimental results show that our robust approach of single model trained on English reviews statistically significantly outperforms the baselines in several different languages.},
archivePrefix = {arXiv},
arxivId = {1806.04511},
author = {Can, Ethem F. and Ezen-Can, Aysu and Can, Fazli},
eprint = {1806.04511},
file = {:D$\backslash$:/ATIML/RNN sentiment.pdf:pdf},
keywords = {deep learning,does not utilize any,goal is to evaluate,how well a generic,lexicons,model can be used,multilingual nlp,our,sentiment analysis,sentiment analysis model that,to mine,•Computing methodologies  Natural language processing,•Information systems  Content analysis and feature selection},
title = {{Multilingual Sentiment Analysis: An RNN-Based Framework for Limited Data}},
url = {http://arxiv.org/abs/1806.04511},
year = {2018}
}
@article{Pieters2018,
abstract = {We compare classic text classification techniques with more recent machine learning techniques and introduce a novel architecture that outperforms many state-of-the-art approaches. These techniques are evaluated on a new multi-label classification task, where the task is to predict the genre of a movie based on its subtitle. We show that pre-trained word embeddings contain ‘universal' features by using the Semantic-Syntactic Word Relationship test. Furthermore, we explore the effectiveness of a convolutional neural network (CNN) that can extract local features, and a long short term memory network (LSTM) that can find time-dependent relationships. By combining a CNN with an LSTM we observe a strong performance improvement. The technique that performs best is a multi-layer perceptron, with as input the bag-of-words model.},
author = {Pieters, Mathijs and Wiering, Marco},
doi = {10.1007/978-3-319-76892-2_10},
file = {:D$\backslash$:/ATIML/comparison{\_}of{\_}machine{\_}learning{\_}techniques-1.pdf:pdf},
isbn = {9783319768915},
issn = {18650929},
journal = {Communications in Computer and Information Science},
keywords = {Bag-of-words model,CNN model,LSTM network,Movie subtitles,Multi-label text classification,Natural language processing},
pages = {131--144},
title = {{Comparison of machine learning techniques for multi-label genre classification}},
volume = {823},
year = {2018}
}
@article{Polleya,
author = {Polley, Sayantan and Thiel, Marcus and Kotzyba, Michael and Andreas, N},
file = {:C$\backslash$:/Users/Lenovo/Downloads/ICHMS2020{\_}paper{\_}42.pdf:pdf},
title = {{SIMFIC : An Explainable Book Search Companion}}
}
@article{Polley,
author = {Polley, Sayantan and Ghosh, Suhita},
file = {:C$\backslash$:/Users/Lenovo/Downloads/SIMFIC{\_}LNCS.pdf:pdf},
keywords = {english fiction,gutenberg,text retrieval},
title = {{Comparing the qualitative impact of different features and similarities on fictional text using SIMFIC}}
}
